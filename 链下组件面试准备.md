### 🟡 **cmd 模块：如何描述 CLI 框架的生命周期控制优势？**

> 本项目采用的是 `urfave/cli` 框架，它天然支持生命周期控制，比如 `Before`, `After`, `Action` 等钩子函数。我们在 `start` 和 `stop` 函数中，能够精确控制组件初始化与关闭的顺序，避免资源泄露或启动顺序混乱。相比 cobra，它更加强调“运行期行为封装”，比如服务启动、链下监听、DB连接、Worker调度等，可以统一在 `cli.Action` 中完成控制，形成一个天然的生命周期管理中心。

### 🟡 **两个 ethclient 设置细节的补充说明？**

> 我们使用两个 ethclient 实例进行职责分离。
> 监听/同步的 client 会配置更高的连接超时（如 10s），更强的 keep-alive 策略，保证链同步稳定；
> 而用于状态读取的 client 我们设置更短的超时时间（如 3s），快速失败、快速 fallback，这样能最大限度避免卡顿拖垮业务处理流程。

### 🟡 **Synchronizer 的执行顺序上下游依赖？**

> Synchronizer 是在主入口中最早启动的模块之一，它依赖于数据库初始化成功，并确保 Redis 等缓存系统 ready 才开始运行。
> 其职责是为后续的事件解析器和 worker 提供同步过的区块头和日志数据，因此必须**优先于 EventParser 和 Worker 启动，并确保其状态对齐**后才能触发下游逻辑。

### 🟡 **Synchronizer 的存储是否异步？是否具备幂等性？**

> 区块头和事件日志的写入是同步阻塞进行的，为了保证系统的可恢复性和幂等性，我们在数据库写入层做了**主键冲突忽略机制**，并通过事务管理和 retry 保证了写入一致性。每个区块和事件在插入前都会判断唯一哈希或高度，避免重复处理。

---

### 🟡 **EventParser：为什么要用 ABI 解码事件？**

> 这是面试高频问题。
> 我会说，链上的日志结构中 `topics[0]` 是事件签名的 keccak256 哈希，只能识别事件名，而事件的参数并不会暴露出来。因此我们必须通过 ABI 解码 log.data 和 log.topics[1:]，才能正确还原事件参数。通过 go-ethereum 提供的 unpack 方式，ABI 提供的 `ParseRequestSent` 方法能精准获取参数结构并绑定到强类型结构体中。

### 🟡 **EventParser 和 Worker 是否解耦？**

> 是的，它们之间通过数据库解耦。EventParser 会将解析好的 RequestSent 等事件写入事件表，Worker 会从该表中拉取待处理事件，这样可以保证模块独立、容错性强，即使某个模块 crash，也不会导致整个流程中断。


---

### 🟡 **数据库迁移：ExecuteSQLMigration 是否支持幂等？**

> 支持的。我们采用标准的 `golang-migrate` 风格，每条 SQL migration 都配有唯一版本号，在迁移表中做记录，确保重复执行不会报错。这样无论是本地开发还是上线部署，都可以安全地重复执行 migration，确保 DB 结构完整。

### 🟡 **worker 使用 raw contract 的意义？**

> 使用 `bind.BoundContract` 能跳过 go binding 的默认参数控制，例如 gasLimit、gasPrice 等，这对我们手动控制交易行为非常关键。比如我们需要动态设置 gas 或 EIP-1559 参数，这些在 raw contract 中可以灵活配置。而强类型合约则用于参数结构绑定，两者结合非常灵活。

### 🟡 **txmgr 是否处理 nonce 管理与重试？**

> 是的，我们自研的 `txmgr` 实现包含 nonce 管理、交易重试、链上确认等机制。通过本地缓存和链上确认机制结合，能在多协程环境下避免 nonce 冲突，并且在交易失败时自动回退重发，直到交易被确认或者失败退出，保障交易可用性和准确性

### 🟡 **abis & go bindings：为什么使用 abigen？**

> 使用 `abigen` 可以将合约 ABI 编译成 Go 的强类型结构体，让我们以类似调用本地方法的方式来操作合约函数。这大幅降低了出错率，提升了开发效率，也能借助 IDE 自动补全和类型检查。此外我们也保留 raw ABI 结构用于需要手动控制 gas 或特殊签名解析的场景。

### 🟡 **configs & flags 设计亮点？**

> 我们通过 CLI 参数配置 chainId、环境变量、RPC 地址、数据库路径等运行时变量，配合 `viper` / `flag` 解析逻辑，可以实现一套代码多环境部署，如 testnet/dev/mainnet 切换等，确保开发与上线环境解耦。

### 🟡 **Redis / 消息队列用在什么地方？**

> Redis 主要用于缓存最近处理区块高度、事件去重标识或限流标志，用于提升系统性能。消息队列（如果接入）一般用于链上事件异步推送到业务服务，比如通知系统或后端 API，通过解耦主流程与用户响应系统，提升吞吐。

### 🟡 **API路由逻辑没写，是因为本项目没有 HTTP API？**

> 是的，这个链下服务本质是一个“链同步-事件解析-交易发送”三段式数据处理服务，不提供 RESTful API 接口，因此没有常规 API 路由模块。这也说明它更偏向后台处理系统而不是业务服务系统。

### **建议加入的面试准备内容**

🟡 以下是你总结中暂未提及但建议准备的：

1. **上下游模块解耦设计原则**
    
    - 通过 db/mq 等手段将区块同步、事件解析、交易发送分离
    
        
2. **故障恢复机制**
    
    - 如何断点续传？如果进程意外终止后如何继续处理？
        
3. **链回滚处理逻辑**
    
    - 是否有设计 checkpoint/回滚检测（比如区块 hash 检查失败如何处理）？
        
4. **性能优化策略**
    
    - 比如批量插入日志 vs 单条写入，txMgr 的并发限制等
        
5. **测试和验证机制**
    
    - 单元测试框架？合约事件验证？链下逻辑测试？


### 🟡 **1. 上下游模块解耦设计原则**

> **面试问题**：你们链下服务是如何做模块解耦的？模块之间如何通信？

> **答题框架**：谈设计原则（高内聚、低耦合）→ 具体做法（DB、MQ）→ 好处（容错、扩展）

> **参考回答**：

> 我们的链下服务设计采用了**“区块同步 - 事件解析 - 交易发送”**三段式架构，三个模块分别由 `Synchronizer`、`EventParser` 和 `Worker` 负责。
> 
> 它们之间通过数据库完成解耦，例如：
> 
> - Synchronizer 把同步到的区块和合约事件写入 DB；
>     
> - EventParser 解析这些事件并写入结构化事件表；
>     
> - Worker 从事件表中筛选需要发送交易的事件处理；
>     
> 
> 这样的好处是即使某个模块 crash 或被重启，也不会影响整个服务流程，具备较好的**容错能力与模块独立性**。如果后续需要替换某一模块，如换掉事件解析规则，也不影响链同步或交易发送。

### 🟡 **2. 故障恢复机制 / 断点续传**

> **面试问题**：如果链下服务中断，你是如何保证下次启动能从断点恢复的？

> **答题框架**：谈持久化点 → 如何读取 → 恢复策略 → 幂等性保障

> **参考回答**：

> 我们通过**区块高度持久化 + 状态表**的方式来实现断点续传：
> 
> - `Synchronizer` 每次同步后会记录最新处理的 `block_number` 到数据库；
>     
> - `EventParser` 同样记录“最近处理过的区块高度”作为起点；
>     
> - `Worker` 会根据事件状态标记（例如状态为 pending）来筛选还未处理的事件；
>     
> 
> 因为所有模块都是“读 → 处理 → 写入状态”三段式流程，并且数据库写入具备幂等性，因此即使系统意外终止，重启后也能**从上次断点精准恢复**，不会造成事件遗漏或重复处理。

### 🟡 **3. 链回滚处理逻辑 / 区块一致性验证**

> **面试问题**：如果链发生回滚，你们系统如何发现？如何处理？

> **答题框架**：谈链回滚产生的原因 → 我们的检查逻辑 → 检测机制 → 应对方式

> **参考回答**：

> 链回滚可能出现在重组区块、共识分叉等场景。我们主要通过以下方式来检测链回滚：
> 
> - 在 `headerTraversal.NextHeaders()` 时，每批新区块都会将第一个新区块的 `parentHash` 与本地最新存储的区块的 `hash` 做比对；
>     
> - 如果发现不匹配，说明链回滚或 fork 发生，此时我们会触发一个“回滚重置逻辑”；
>     
> - 具体做法是：将数据库中的区块和事件数据回滚到公共祖先区块高度，重新开始同步；
>     
> 
> 这样可以避免链下数据与链上状态不一致，保持数据准确性。

### 🟡 **4. 性能优化策略**

> **面试问题**：你们做了哪些性能优化？如何提升吞吐量？

> **答题框架**：谈高频操作 → 批量处理 → 并发策略 → 避免阻塞

> **参考回答**：

> 我们做过一些链下服务的性能优化，主要包括：
> 
> - **批量插入区块与事件数据**：在 `processBatch()` 中，统一批量插入区块头和事件，减少 DB I/O 次数；
>     
> - **多 goroutine 并发解析事件**：EventParser 对多个合约事件可并发处理；
>     
> - **txmgr 控制交易并发度**：限制同时发送交易数，避免 nonce 冲突；
>     
> - **合理设置 ethclient 超时时间与重试策略**，避免网络抖动拖慢整体流程；
>     
> - **日志优化**：仅记录关键节点或错误日志，避免大量 I/O 写盘影响主线程。


### 🟡 **5. 测试与验证机制**

> **面试问题**：链下服务如何测试？如何确保稳定性？

> **答题框架**：谈单测 → 合约事件验证 → 集成测试 or 模拟链

> **参考回答**：

> 我们从几个维度保证链下服务的可靠性：
> 
> - **单元测试**：对区块解析、事件转换、交易构造等模块都有单测，模拟 ABI 解码、日志反序列化等场景；
>     
> - **事件回放验证**：使用历史区块和事件日志，通过 ABI 重解码，验证解析逻辑和数据库入库是否一致；
>     
> - **合约端 Mock 环境测试**：搭配本地私链（如 Hardhat 或 Ganache），部署测试合约并发送事件进行全链路模拟；
>     
> - **交易发送流程测试**：通过构造伪交易，在 dry-run 模式下测试交易构造和签名是否正常；
>     
> 
> 通过这些手段，我们确保上线前逻辑完整、链下链上行为一致。